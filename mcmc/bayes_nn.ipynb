{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6095a29152a3dc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T20:33:06.550493Z",
     "start_time": "2024-05-09T20:33:05.576476Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro import handlers\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "from mcmc import run_lmc_numpyro\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")  # noqa: E402\n",
    "\n",
    "\n",
    "# a two-layer bayesian neural network with computational flow\n",
    "# given by D_X => D_H => D_H => D_Y where D_H is the number of\n",
    "# hidden units. (note we indicate tensor dimensions in the comments)\n",
    "def model(X, Y, D_H, D_Y=1):\n",
    "    N, D_X = X.shape\n",
    "\n",
    "    # sample first layer (we put unit normal priors on all weights)\n",
    "    w1 = numpyro.sample(\"w1\", dist.Normal(jnp.zeros((D_X, D_H)), jnp.ones((D_X, D_H))))\n",
    "    assert w1.shape == (D_X, D_H)\n",
    "    z1 = jnp.tanh(jnp.matmul(X, w1))  # <= first layer of activations\n",
    "    assert z1.shape == (N, D_H)\n",
    "\n",
    "    # sample second layer\n",
    "    w2 = numpyro.sample(\"w2\", dist.Normal(jnp.zeros((D_H, D_H)), jnp.ones((D_H, D_H))))\n",
    "    assert w2.shape == (D_H, D_H)\n",
    "    z2 = jnp.tanh(jnp.matmul(z1, w2))  # <= second layer of activations\n",
    "    assert z2.shape == (N, D_H)\n",
    "\n",
    "    # sample final layer of weights and neural network output\n",
    "    w3 = numpyro.sample(\"w3\", dist.Normal(jnp.zeros((D_H, D_Y)), jnp.ones((D_H, D_Y))))\n",
    "    assert w3.shape == (D_H, D_Y)\n",
    "    z3 = jnp.matmul(z2, w3)  # <= output of the neural network\n",
    "    assert z3.shape == (N, D_Y)\n",
    "\n",
    "    if Y is not None:\n",
    "        assert z3.shape == Y.shape\n",
    "\n",
    "    # we put a prior on the observation noise\n",
    "    prec_obs = numpyro.sample(\"prec_obs\", dist.Gamma(3.0, 1.0))\n",
    "    sigma_obs = 1.0 / jnp.sqrt(prec_obs)\n",
    "\n",
    "    # observe data\n",
    "    with numpyro.plate(\"data\", N):\n",
    "        # note we use to_event(1) because each observation has shape (1,)\n",
    "        numpyro.sample(\"Y\", dist.Normal(z3, sigma_obs).to_event(1), obs=Y)\n",
    "\n",
    "\n",
    "# helper function for HMC inference\n",
    "def run_inference(model, num_warmup, num_samples, num_chains, rng_key, X, Y, D_H):\n",
    "    start = time.time()\n",
    "    kernel = NUTS(model)\n",
    "    mcmc = MCMC(\n",
    "        kernel,\n",
    "        num_warmup=num_warmup,\n",
    "        num_samples=num_samples,\n",
    "        num_chains=num_chains,\n",
    "        progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True,\n",
    "    )\n",
    "    mcmc.run(rng_key, X, Y, D_H)\n",
    "    mcmc.print_summary()\n",
    "    print(\"\\nMCMC elapsed time:\", time.time() - start)\n",
    "    return mcmc.get_samples()\n",
    "\n",
    "\n",
    "def run_inference_lmc(model, num_warmup, num_samples, num_chains, rng_key, X, Y, D_H):\n",
    "    start = time.time()\n",
    "    samples, steps = run_lmc_numpyro(\n",
    "        jr.key(0),\n",
    "        model,\n",
    "        (X, Y, D_H),\n",
    "        num_particles=num_chains,\n",
    "        chain_len=num_samples,\n",
    "        warmup_mult=num_warmup,\n",
    "        tol=0.1,\n",
    "        chain_sep=0.25,\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\nLMC elapsed time: {elapsed:.4}, num_steps: {steps}\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "# helper function for prediction\n",
    "def predict(model, rng_key, samples, X, D_H):\n",
    "    model = handlers.substitute(handlers.seed(model, rng_key), samples)\n",
    "    # note that Y will be sampled in the model because we pass Y=None here\n",
    "    model_trace = handlers.trace(model).get_trace(X=X, Y=None, D_H=D_H)\n",
    "    return model_trace[\"Y\"][\"value\"]\n",
    "\n",
    "\n",
    "# create artificial regression dataset\n",
    "def get_data(N=50, D_X=3, sigma_obs=0.05, N_test=500):\n",
    "    D_Y = 1  # create 1d outputs\n",
    "    np.random.seed(0)\n",
    "    X = jnp.linspace(-1, 1, N)\n",
    "    X = jnp.power(X[:, np.newaxis], jnp.arange(D_X))\n",
    "    W = 0.5 * np.random.randn(D_X)\n",
    "    Y = jnp.dot(X, W) + 0.5 * jnp.power(0.5 + X[:, 1], 2.0) * jnp.sin(4.0 * X[:, 1])\n",
    "    Y += sigma_obs * np.random.randn(N)\n",
    "    Y = Y[:, np.newaxis]\n",
    "    Y -= jnp.mean(Y)\n",
    "    Y /= jnp.std(Y)\n",
    "\n",
    "    assert X.shape == (N, D_X)\n",
    "    assert Y.shape == (N, D_Y)\n",
    "\n",
    "    X_test = jnp.linspace(-1.3, 1.3, N_test)\n",
    "    X_test = jnp.power(X_test[:, np.newaxis], jnp.arange(D_X))\n",
    "\n",
    "    return X, Y, X_test\n",
    "\n",
    "\n",
    "def main(\n",
    "    num_data=50,\n",
    "    num_hidden=5,\n",
    "    num_samples=2000,\n",
    "    num_warmup=1000,\n",
    "    num_chains=1,\n",
    "    use_lmc=False,\n",
    "):\n",
    "    N, D_X, D_H = num_data, 3, num_hidden\n",
    "    X, Y, X_test = get_data(N=N, D_X=D_X)\n",
    "\n",
    "    # do inference\n",
    "    rng_key, rng_key_predict = jr.split(jr.PRNGKey(0))\n",
    "\n",
    "    inference_fun = run_inference_lmc if use_lmc else run_inference\n",
    "    samples = inference_fun(\n",
    "        model, num_warmup, num_samples, num_chains, rng_key, X, Y, D_H\n",
    "    )\n",
    "\n",
    "    # predict Y_test at inputs X_test\n",
    "    vmap_args = (\n",
    "        samples,\n",
    "        jr.split(rng_key_predict, num_samples * num_chains),\n",
    "    )\n",
    "    predictions = jax.jit(\n",
    "        jax.vmap(lambda samples, rng_key: predict(model, rng_key, samples, X_test, D_H))\n",
    "    )(*vmap_args)\n",
    "    predictions = predictions[..., 0]\n",
    "\n",
    "    # compute mean prediction and confidence interval around median\n",
    "    mean_prediction = jnp.mean(predictions, axis=0)\n",
    "    percentiles = np.percentile(predictions, [5.0, 95.0], axis=0)\n",
    "\n",
    "    # make plots\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "\n",
    "    # plot training data\n",
    "    ax.plot(X[:, 1], Y[:, 0], \"kx\")\n",
    "    # plot 90% confidence level of predictions\n",
    "    ax.fill_between(\n",
    "        X_test[:, 1], percentiles[0, :], percentiles[1, :], color=\"lightblue\"\n",
    "    )\n",
    "    # plot mean prediction\n",
    "    ax.plot(X_test[:, 1], mean_prediction, \"blue\", ls=\"solid\", lw=2.0)\n",
    "    ax.set(xlabel=\"X\", ylabel=\"Y\", title=\"Mean predictions with 90% CI\")\n",
    "\n",
    "    plt.savefig(\"bnn_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7d3e347a41519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T20:34:39.203692Z",
     "start_time": "2024-05-09T20:33:07.022734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████| [00:01<00:00, 82.77%/s]\n",
      "100.00%|██████████| [01:00<00:00,  1.65%/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMC: gradient evaluations per output: 81.54\n",
      "\n",
      "LMC elapsed time: 91.84, num_steps: 81.538330078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N, D_X, D_H = 50, 3, 5\n",
    "X, Y, X_test = get_data(N=N, D_X=D_X)\n",
    "\n",
    "# do inference\n",
    "rng_key, rng_key_predict = jr.split(jr.PRNGKey(0))\n",
    "\n",
    "samples = run_inference_lmc(model, 16, 2**8, 2**5, rng_key, X, Y, D_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7348429d7b1e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T20:34:52.327236Z",
     "start_time": "2024-05-09T20:34:52.324529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prec_obs': (32, 256), 'w1': (32, 256, 3, 5), 'w2': (32, 256, 5, 5), 'w3': (32, 256, 5, 1)}\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "\n",
    "\n",
    "print(jtu.tree_map(lambda x: x.shape, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fe7ea2ccd3227b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T18:56:17.374307Z",
     "start_time": "2024-05-09T18:12:21.592456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████| [11:05<00:00,  6.65s/%]\n",
      "100.00%|██████████| [32:22<00:00, 19.43s/%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMC: gradient evaluations per output: 367.9\n",
      "\n",
      "LMC elapsed time: 2.635e+03, num_steps: 367.8780212402344\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (4 of them) had size 1, e.g. axis 0 of argument samples['prec_obs'] of type float32[1,2000];\n  * one axis had size 2000: axis 0 of argument rng_key of type uint32[2000,2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_lmc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 130\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(num_data, num_hidden, num_samples, num_warmup, num_chains, use_lmc)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# predict Y_test at inputs X_test\u001b[39;00m\n\u001b[1;32m    126\u001b[0m vmap_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    127\u001b[0m     samples,\n\u001b[1;32m    128\u001b[0m     jr\u001b[38;5;241m.\u001b[39msplit(rng_key_predict, num_samples \u001b[38;5;241m*\u001b[39m num_chains),\n\u001b[1;32m    129\u001b[0m )\n\u001b[0;32m--> 130\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_H\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# compute mean prediction and confidence interval around median\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "File \u001b[0;32m~/PycharmProjects/diffrax_STLA/venv/lib/python3.11/site-packages/jax/_src/api.py:1322\u001b[0m, in \u001b[0;36m_mapped_axis_size\u001b[0;34m(fn, tree, vals, dims, name)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1321\u001b[0m     msg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  * some axes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of them) had size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, e.g. axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1322\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (4 of them) had size 1, e.g. axis 0 of argument samples['prec_obs'] of type float32[1,2000];\n  * one axis had size 2000: axis 0 of argument rng_key of type uint32[2000,2]"
     ]
    }
   ],
   "source": [
    "main(use_lmc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3921858d05edf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 3000/3000 [07:50<00:00,  6.37it/s, 511 steps of size 7.39e-03. acc. prob=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "  prec_obs     11.56      2.41     11.39      7.50     15.27   2071.61      1.00\n",
      "   w1[0,0]      0.10      1.16      0.18     -1.72      2.07    294.63      1.00\n",
      "   w1[0,1]     -0.07      1.13     -0.15     -1.89      1.83    265.78      1.02\n",
      "   w1[0,2]     -0.10      1.16     -0.14     -1.89      1.78    343.29      1.01\n",
      "   w1[0,3]     -0.09      1.21     -0.18     -1.93      1.98    302.05      1.00\n",
      "   w1[0,4]      0.08      1.11      0.09     -1.61      1.99    255.54      1.00\n",
      "   w1[1,0]     -0.10      1.16     -0.15     -1.83      1.75    177.52      1.00\n",
      "   w1[1,1]      0.14      1.12      0.21     -1.63      1.83    106.35      1.06\n",
      "   w1[1,2]      0.01      1.13      0.03     -1.71      1.89    323.59      1.00\n",
      "   w1[1,3]      0.19      1.13      0.30     -1.69      1.87    286.64      1.01\n",
      "   w1[1,4]     -0.07      1.17     -0.12     -1.83      1.82    200.40      1.00\n",
      "   w1[2,0]     -0.13      1.17     -0.12     -2.00      1.79    199.29      1.00\n",
      "   w1[2,1]      0.17      1.18      0.18     -1.75      2.07    151.49      1.05\n",
      "   w1[2,2]      0.01      1.12      0.02     -1.73      1.94    261.63      1.00\n",
      "   w1[2,3]      0.15      1.14      0.11     -1.62      1.97    291.62      1.02\n",
      "   w1[2,4]     -0.12      1.18     -0.15     -1.95      1.87    199.86      1.00\n",
      "   w2[0,0]      0.02      1.06      0.03     -1.89      1.64   1042.43      1.00\n",
      "   w2[0,1]     -0.02      1.03      0.00     -1.72      1.62   1179.92      1.00\n",
      "   w2[0,2]      0.01      1.06      0.04     -1.76      1.78   1158.46      1.00\n",
      "   w2[0,3]      0.01      1.09      0.01     -1.61      1.93    999.59      1.00\n",
      "   w2[0,4]      0.05      1.10      0.05     -1.72      1.89    961.07      1.00\n",
      "   w2[1,0]     -0.03      1.07     -0.04     -1.72      1.76   1030.03      1.00\n",
      "   w2[1,1]     -0.05      1.05     -0.05     -1.89      1.54    817.78      1.00\n",
      "   w2[1,2]     -0.01      1.07     -0.01     -1.83      1.70    961.56      1.01\n",
      "   w2[1,3]      0.02      1.06      0.01     -1.81      1.61    796.82      1.00\n",
      "   w2[1,4]     -0.00      1.09     -0.00     -1.78      1.77    982.04      1.00\n",
      "   w2[2,0]     -0.03      1.03     -0.03     -1.76      1.59   1163.03      1.00\n",
      "   w2[2,1]     -0.01      1.07      0.00     -1.68      1.78   1066.36      1.00\n",
      "   w2[2,2]     -0.00      1.04     -0.00     -1.69      1.68   1157.26      1.00\n",
      "   w2[2,3]      0.04      1.07      0.05     -1.61      1.81    924.60      1.00\n",
      "   w2[2,4]     -0.01      1.06      0.06     -1.67      1.74   1250.50      1.00\n",
      "   w2[3,0]     -0.04      1.07     -0.04     -1.81      1.71    949.42      1.00\n",
      "   w2[3,1]     -0.07      1.07     -0.10     -1.79      1.66   1048.88      1.00\n",
      "   w2[3,2]      0.02      1.08      0.03     -1.80      1.69    875.56      1.00\n",
      "   w2[3,3]     -0.00      1.10     -0.01     -1.79      1.84   1207.41      1.00\n",
      "   w2[3,4]      0.01      1.07      0.01     -1.77      1.74    955.97      1.00\n",
      "   w2[4,0]      0.02      1.08      0.02     -1.78      1.70   1078.39      1.00\n",
      "   w2[4,1]      0.01      1.04      0.01     -1.69      1.63    979.99      1.00\n",
      "   w2[4,2]      0.00      1.08     -0.01     -1.81      1.73    858.22      1.00\n",
      "   w2[4,3]      0.01      1.08      0.02     -1.82      1.75    943.61      1.00\n",
      "   w2[4,4]      0.01      1.07      0.04     -1.78      1.65   1115.75      1.00\n",
      "   w3[0,0]      0.01      1.42     -0.01     -2.32      2.25    428.17      1.00\n",
      "   w3[1,0]     -0.04      1.43     -0.00     -2.35      2.23    465.99      1.00\n",
      "   w3[2,0]      0.02      1.41      0.03     -2.32      2.23    383.60      1.00\n",
      "   w3[3,0]     -0.14      1.42     -0.20     -2.53      2.02    273.37      1.00\n",
      "   w3[4,0]      0.07      1.48      0.10     -2.20      2.54    395.30      1.00\n",
      "\n",
      "Number of divergences: 5\n",
      "\n",
      "MCMC elapsed time: 471.58813309669495\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c54ae8d94f2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

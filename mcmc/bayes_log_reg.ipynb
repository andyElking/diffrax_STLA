{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T07:56:56.769248Z",
     "start_time": "2024-05-09T07:56:56.621461Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n",
      "Data shape: (768, 8)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import ot\n",
    "import scipy\n",
    "from jax import Array\n",
    "from numpyro import diagnostics, distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "from mcmc import run_lmc_numpyro\n",
    "\n",
    "\n",
    "jnp.set_printoptions(precision=3, suppress=True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "print(jax.devices(\"cuda\"))\n",
    "\n",
    "\n",
    "def get_model_and_data(data, name):\n",
    "    dset = data[name][0, 0]\n",
    "    x = dset[\"x\"]\n",
    "    labels = dset[\"t\"]\n",
    "    n, data_dim = x.shape\n",
    "    print(f\"Data shape: {x.shape}\")\n",
    "    n_train = min(int(n * 0.8), 500)\n",
    "    x_train = x[:n_train]\n",
    "    labels_train = labels[:n_train]\n",
    "    x_test = x[n_train:]\n",
    "    labels_test = labels[n_train:]\n",
    "\n",
    "    def model():\n",
    "        alpha = numpyro.sample(\"alpha\", dist.Exponential(0.01))\n",
    "        W = numpyro.sample(\"W\", dist.Normal(jnp.zeros(data_dim), 1.0 / alpha))\n",
    "        logits = jnp.sum(W * x_train, axis=-1)\n",
    "        return numpyro.sample(\"obs\", dist.Bernoulli(logits=logits), obs=labels_train)\n",
    "\n",
    "    return model, (x_train, labels_train, x_test, labels_test)\n",
    "\n",
    "\n",
    "def compute_w2(x1, x2, num_iters):\n",
    "    source_samples = np.array(x1)\n",
    "    target_samples = np.array(x2)\n",
    "    source_weights = np.ones(source_samples.shape[0]) / source_samples.shape[0]\n",
    "    target_weights = np.ones(target_samples.shape[0]) / target_samples.shape[0]\n",
    "    mm = ot.dist(source_samples, target_samples)\n",
    "    return ot.emd2(source_weights, target_weights, mm, numItermax=num_iters)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"max_len\",))\n",
    "def energy_distance(x: Array, y: Array, max_len: int = 2**15):\n",
    "    assert y.ndim == x.ndim\n",
    "    assert x.shape[1:] == y.shape[1:]\n",
    "    if x.shape[0] > max_len:\n",
    "        x = x[:max_len]\n",
    "    if y.shape[0] > max_len:\n",
    "        y = y[:max_len]\n",
    "\n",
    "    @partial(jax.vmap, in_axes=(None, 0))\n",
    "    def _dist_single(_x, _y_single):\n",
    "        assert _x.ndim == _y_single.ndim + 1, f\"{_x.ndim} != {_y_single.ndim + 1}\"\n",
    "        diff = _x - _y_single\n",
    "        if x.ndim > 1:\n",
    "            # take the norm over all axes except the first one\n",
    "            diff = jnp.sqrt(jnp.sum(diff**2, axis=tuple(range(1, diff.ndim))))\n",
    "        return jnp.mean(jnp.abs(diff))\n",
    "\n",
    "    def dist(_x, _y):\n",
    "        assert _x.ndim == _y.ndim\n",
    "        return jnp.mean(_dist_single(_x, _y))\n",
    "\n",
    "    return 2 * dist(x, y) - dist(x, x) - dist(y, y)\n",
    "\n",
    "\n",
    "def dict_to_array(dct: dict):\n",
    "    alpha = dct[\"alpha\"]\n",
    "    return jnp.concatenate([jnp.expand_dims(alpha, alpha.ndim), dct[\"W\"]], axis=-1)\n",
    "\n",
    "\n",
    "vec_dict_to_array = jax.jit(jax.vmap(dict_to_array, in_axes=0, out_axes=0))\n",
    "\n",
    "\n",
    "def eval_logreg(samples, evals_per_sample, ground_truth=None, num_iters_w2=0):\n",
    "    if isinstance(samples, dict):\n",
    "        samples = vec_dict_to_array(samples)\n",
    "    ess = diagnostics.effective_sample_size(samples)\n",
    "    print(f\"Effective sample size: {ess}\")\n",
    "    # print(\n",
    "    #     f\"Gradient evals per effective sample:\"\n",
    "    #     f\" {evals_per_sample * samples.shape[0]/ess}\"\n",
    "    # )\n",
    "    if ground_truth is None:\n",
    "        return\n",
    "    sample_dim = samples.shape[-1]\n",
    "    reshaped = jnp.reshape(samples, (-1, sample_dim))\n",
    "    energy_gt = energy_distance(reshaped, ground_truth)\n",
    "    half_len = reshaped.shape[0] // 2\n",
    "    energy_self = energy_distance(reshaped[:half_len], reshaped[half_len:])\n",
    "    result_str = (\n",
    "        f\"Energy dist vs ground truth: {energy_gt:.4}, vs self: {energy_self:.4}\"\n",
    "    )\n",
    "    if num_iters_w2 > 0:\n",
    "        w2 = compute_w2(reshaped, ground_truth, num_iters_w2)\n",
    "        result_str += f\", Wasserstein-2: {w2:.4}\"\n",
    "    print(result_str)\n",
    "\n",
    "\n",
    "dataset = scipy.io.loadmat(\"mcmc_data/benchmarks.mat\")\n",
    "data_name = \"diabetis\"\n",
    "model_logreg, data_split = get_model_and_data(dataset, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6890aa66d4af19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T00:31:23.134351Z",
     "start_time": "2024-05-08T19:00:42.065585Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 69632/69632 [5:30:38<00:00,  3.51it/s, 1023 steps of size 1.35e-14. acc. prob=0.81]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy bias: 0.0\n",
      "Ground truth shape: (65536, 9)\n"
     ]
    }
   ],
   "source": [
    "gt_nuts = MCMC(NUTS(model_logreg, step_size=1.0), num_warmup=2**12, num_samples=2**16)\n",
    "gt_nuts.run(jr.PRNGKey(0))\n",
    "gt_logreg = vec_dict_to_array(gt_nuts.get_samples())\n",
    "file_name = f\"mcmc_data/{data_name}_ground_truth_step1.0.npy\"\n",
    "np.save(file_name, gt_logreg)\n",
    "\n",
    "gt_logreg = np.load(file_name)\n",
    "size_gt_half = int(gt_logreg.shape[0] // 2)\n",
    "energy_bias = energy_distance(gt_logreg[:size_gt_half], gt_logreg[size_gt_half:])\n",
    "print(f\"Energy bias: {energy_bias}\")\n",
    "print(f\"Ground truth shape: {gt_logreg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50042810f728a278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T07:58:35.890706Z",
     "start_time": "2024-05-09T07:58:35.886773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.742e-05  1.366e+11  1.391e+05  5.171e+04 -1.843e+04 -2.148e+03\n",
      "  2.220e+03 -3.669e+03  1.833e+07]\n"
     ]
    }
   ],
   "source": [
    "print(gt_logreg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e04f471ab930a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T07:58:36.678909Z",
     "start_time": "2024-05-09T07:58:36.674323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.742e-05  1.366e+11  1.391e+05  5.171e+04 -1.843e+04 -2.148e+03\n",
      "  2.220e+03 -3.669e+03  1.833e+07]\n"
     ]
    }
   ],
   "source": [
    "print(gt_logreg[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34cf991f20286c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T07:58:37.880407Z",
     "start_time": "2024-05-09T07:58:37.876506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.742e-05  1.366e+11  1.391e+05  5.171e+04 -1.843e+04 -2.148e+03\n",
      "  2.220e+03 -3.669e+03  1.833e+07]\n"
     ]
    }
   ],
   "source": [
    "print(gt_logreg[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b866c607224c7d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T12:13:52.237653Z",
     "start_time": "2024-05-08T12:13:03.222314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running warmup  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████| [00:12<00:00,  7.97%/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LMC  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████| [00:18<00:00,  5.42%/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMC: gradient evaluations per output: 92.6\n",
      "{'W': (64, 128, 8), 'alpha': (64, 128)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_chains = 2**6\n",
    "num_samples_per_chain = 2**7\n",
    "out_logreg_lmc, steps_logreg_lmc = run_lmc_numpyro(\n",
    "    jr.PRNGKey(0),\n",
    "    model_logreg,\n",
    "    num_chains,\n",
    "    num_samples_per_chain,\n",
    "    chain_sep=0.25,\n",
    "    tol=0.1,\n",
    "    warmup_mult=128.0,\n",
    "    warmup_tol_mult=4.0,\n",
    ")\n",
    "print(jtu.tree_map(lambda x: x.shape, out_logreg_lmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370c919e1db98307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T23:34:12.636290Z",
     "start_time": "2024-05-07T23:34:11.845160Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_logreg(out_logreg_lmc, steps_logreg_lmc, gt_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47568f0f703122b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T23:35:04.676560Z",
     "start_time": "2024-05-07T23:34:47.833966Z"
    }
   },
   "outputs": [],
   "source": [
    "nuts = MCMC(\n",
    "    NUTS(model_logreg),\n",
    "    num_warmup=2**3,\n",
    "    num_samples=num_samples_per_chain,\n",
    "    num_chains=num_chains,\n",
    "    chain_method=\"vectorized\",\n",
    ")\n",
    "nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)\n",
    "print(geps_nuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cf79276c2501d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T23:35:14.965378Z",
     "start_time": "2024-05-07T23:35:14.639777Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_logreg(out_logreg_nuts, geps_nuts, gt_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b826cca477206d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T12:15:42.349642Z",
     "start_time": "2024-04-26T12:15:42.345573Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_logreg_dataset(name):\n",
    "    model_logreg, data_split = get_model_and_data(dataset, name)\n",
    "\n",
    "    # Compute ground truth\n",
    "    ground_truth_filename = f\"mcmc_data/{name}_ground_truth.npy\"\n",
    "    if os.path.isfile(ground_truth_filename):\n",
    "        ground_truth = np.load(ground_truth_filename)\n",
    "    else:\n",
    "        gt_nuts = MCMC(\n",
    "            NUTS(model_logreg, step_size=0.125), num_warmup=2**13, num_samples=2**15\n",
    "        )\n",
    "        gt_nuts.run(jr.PRNGKey(0))\n",
    "        ground_truth = vec_dict_to_array(gt_nuts.get_samples())\n",
    "        np.save(f\"mcmc_data/{name}_ground_truth.npy\", ground_truth)\n",
    "    size_gt_half = int(ground_truth.shape[0] // 2)\n",
    "    gt_energy_bias = energy_distance(\n",
    "        ground_truth[:size_gt_half], ground_truth[size_gt_half:]\n",
    "    )\n",
    "    print(f\"Ground truth energy bias: {gt_energy_bias:.4}\")\n",
    "    num_chains = 2**7\n",
    "    num_samples_per_chain = 2**8\n",
    "\n",
    "    out_logreg_lmc, steps_logreg_lmc = run_lmc_numpyro(\n",
    "        jr.PRNGKey(0),\n",
    "        model_logreg,\n",
    "        num_chains,\n",
    "        num_samples_per_chain,\n",
    "        chain_sep=0.25,\n",
    "        tol=0.1,\n",
    "        warmup_mult=128.0,\n",
    "        warmup_tol_mult=8.0,\n",
    "    )\n",
    "    eval_logreg(out_logreg_lmc, steps_logreg_lmc, ground_truth)\n",
    "\n",
    "    nuts = MCMC(\n",
    "        NUTS(model_logreg),\n",
    "        num_warmup=2**8,\n",
    "        num_samples=num_samples_per_chain,\n",
    "        num_chains=num_chains,\n",
    "        chain_method=\"vectorized\",\n",
    "    )\n",
    "    nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "    out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "    num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "    geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)\n",
    "    print(f\"NUTS: Gradient evals per output: {geps_nuts:.4}\")\n",
    "    eval_logreg(out_logreg_nuts, geps_nuts, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6851c76c27702f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T12:15:43.820119Z",
     "start_time": "2024-04-26T12:15:43.817933Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"banana\",\n",
    "    \"breast_cancer\",\n",
    "    \"diabetis\",\n",
    "    \"flare_solar\",\n",
    "    \"german\",\n",
    "    \"heart\",\n",
    "    \"image\",\n",
    "    \"ringnorm\",\n",
    "    \"splice\",\n",
    "    \"thyroid\",\n",
    "    \"titanic\",\n",
    "    \"twonorm\",\n",
    "    \"waveform\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e926ca753859d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T22:06:31.672723Z",
     "start_time": "2024-04-26T12:15:47.778178Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for name in names:\n",
    "        print(f\"==================== {name} ====================\")\n",
    "        run_logreg_dataset(name)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0934ba3585949a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

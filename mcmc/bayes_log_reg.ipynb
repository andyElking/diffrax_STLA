{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:31:43.487202Z",
     "start_time": "2024-06-07T15:31:42.044150Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAX_PLATFORM_NAME=cuda\n",
      "[cuda(id=0)]\n",
      "Data shape: (5300, 2)\n"
     ]
    }
   ],
   "source": [
    "%env JAX_PLATFORM_NAME=cuda\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import ot\n",
    "import scipy\n",
    "from jax import Array\n",
    "from numpyro import diagnostics, distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "from mcmc import run_lmc_numpyro\n",
    "\n",
    "\n",
    "jnp.set_printoptions(precision=3, suppress=True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "print(jax.devices(\"cuda\"))\n",
    "\n",
    "\n",
    "def get_model_and_data(data, name):\n",
    "    dset = data[name][0, 0]\n",
    "    x = dset[\"x\"]\n",
    "    labels = jnp.squeeze(dset[\"t\"])\n",
    "    # labels are -1 and 1, convert to 0 and 1\n",
    "    labels = (labels + 1) / 2\n",
    "    n, data_dim = x.shape\n",
    "    print(f\"Data shape: {x.shape}\")\n",
    "\n",
    "    # randomly shuffle the data\n",
    "    perm = jax.random.permutation(jr.PRNGKey(0), n)\n",
    "    x = x[perm]\n",
    "    labels = labels[perm]\n",
    "\n",
    "    n_train = min(int(n * 0.8), 1000)\n",
    "    x_train = x[:n_train]\n",
    "    labels_train = labels[:n_train]\n",
    "    x_test = x[n_train:]\n",
    "    labels_test = labels[n_train:]\n",
    "\n",
    "    def model(x, labels):\n",
    "        alpha = numpyro.sample(\"alpha\", dist.Exponential(0.01))\n",
    "        W = numpyro.sample(\"W\", dist.Normal(jnp.zeros(data_dim), 1.0 / alpha))\n",
    "        b = numpyro.sample(\"b\", dist.Normal(jnp.zeros((1,)), 1.0 / alpha))\n",
    "        logits = jnp.sum(W * x + b, axis=-1)\n",
    "        return numpyro.sample(\"obs\", dist.Bernoulli(logits=logits), obs=labels)\n",
    "\n",
    "    return model, (x_train, labels_train, x_test, labels_test)\n",
    "\n",
    "\n",
    "def compute_w2(x1, x2, num_iters):\n",
    "    source_samples = np.array(x1)\n",
    "    target_samples = np.array(x2)\n",
    "    source_weights = np.ones(source_samples.shape[0]) / source_samples.shape[0]\n",
    "    target_weights = np.ones(target_samples.shape[0]) / target_samples.shape[0]\n",
    "    mm = ot.dist(source_samples, target_samples)\n",
    "    return ot.emd2(source_weights, target_weights, mm, numItermax=num_iters)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"max_len\",))\n",
    "def energy_distance(x: Array, y: Array, max_len: int = 2**15):\n",
    "    assert y.ndim == x.ndim\n",
    "    assert x.shape[1:] == y.shape[1:]\n",
    "    if x.shape[0] > max_len:\n",
    "        x = x[:max_len]\n",
    "    if y.shape[0] > max_len:\n",
    "        y = y[:max_len]\n",
    "\n",
    "    @partial(jax.vmap, in_axes=(None, 0))\n",
    "    def _dist_single(_x, _y_single):\n",
    "        assert _x.ndim == _y_single.ndim + 1, f\"{_x.ndim} != {_y_single.ndim + 1}\"\n",
    "        diff = _x - _y_single\n",
    "        if x.ndim > 1:\n",
    "            # take the norm over all axes except the first one\n",
    "            diff = jnp.sqrt(jnp.sum(diff**2, axis=tuple(range(1, diff.ndim))))\n",
    "        return jnp.mean(jnp.abs(diff))\n",
    "\n",
    "    def dist(_x, _y):\n",
    "        assert _x.ndim == _y.ndim\n",
    "        return jnp.mean(_dist_single(_x, _y))\n",
    "\n",
    "    return 2 * dist(x, y) - dist(x, x) - dist(y, y)\n",
    "\n",
    "\n",
    "def dict_to_array(dct: dict):\n",
    "    alpha = dct[\"alpha\"]\n",
    "    alpha = jnp.expand_dims(alpha, alpha.ndim)\n",
    "    b = dct[\"b\"]\n",
    "    return jnp.concatenate([alpha, b, dct[\"W\"]], axis=-1)\n",
    "\n",
    "\n",
    "vec_dict_to_array = jax.jit(jax.vmap(dict_to_array, in_axes=0, out_axes=0))\n",
    "\n",
    "\n",
    "def predict(x, samples):\n",
    "    sum = jnp.sum(samples[:, 2:] * x + samples[:, 1:2], axis=-1)\n",
    "    # apply sigmoid\n",
    "    return 1.0 / (1.0 + jnp.exp(-sum))\n",
    "\n",
    "\n",
    "def test_accuracy(x_test, labels_test, samples):\n",
    "    if isinstance(samples, dict):\n",
    "        samples = vec_dict_to_array(samples)\n",
    "    sample_dim = samples.shape[-1]\n",
    "    samples = jnp.reshape(samples, (-1, sample_dim))\n",
    "    if samples.shape[0] > 2**10:\n",
    "        samples = samples[: 2**10]\n",
    "\n",
    "    func = jax.jit(jax.vmap(lambda x: predict(x, samples), in_axes=0, out_axes=0))\n",
    "    predictions = func(x_test)\n",
    "    assert predictions.shape == (\n",
    "        labels_test.shape[0],\n",
    "        samples.shape[0],\n",
    "    ), f\"{predictions.shape} != {(labels_test.shape[0], samples.shape[0])}\"\n",
    "\n",
    "    labels_test = jnp.reshape(labels_test, (labels_test.shape[0], 1))\n",
    "    is_correct = jnp.abs(predictions - labels_test) < 0.5\n",
    "    accuracy_per_sample = jnp.mean(is_correct, axis=0)\n",
    "\n",
    "    avg_accuracy = jnp.mean(accuracy_per_sample)\n",
    "\n",
    "    len90 = int(0.9 * accuracy_per_sample.shape[0])\n",
    "    best_sorted = jnp.sort(accuracy_per_sample)[:len90]\n",
    "    accuracy_best90 = jnp.mean(best_sorted)\n",
    "    return avg_accuracy, accuracy_best90\n",
    "\n",
    "\n",
    "def eval_logreg(\n",
    "    samples,\n",
    "    evals_per_sample,\n",
    "    ground_truth=None,\n",
    "    num_iters_w2=0,\n",
    "    x_test=None,\n",
    "    labels_test=None,\n",
    "):\n",
    "    if isinstance(samples, dict):\n",
    "        samples = vec_dict_to_array(samples)\n",
    "    ess = diagnostics.effective_sample_size(samples)\n",
    "    print(f\"Effective sample size: {ess}\")\n",
    "    # print(\n",
    "    #     f\"Gradient evals per effective sample:\"\n",
    "    #     f\" {evals_per_sample * samples.shape[0]/ess}\"\n",
    "    # )\n",
    "    sample_dim = samples.shape[-1]\n",
    "    reshaped = jnp.reshape(samples, (-1, sample_dim))\n",
    "\n",
    "    half_len = reshaped.shape[0] // 2\n",
    "    energy_self = energy_distance(reshaped[:half_len], reshaped[half_len:])\n",
    "    result_str = f\"Energy dist vs self: {energy_self:.4}\"\n",
    "\n",
    "    if ground_truth is not None:\n",
    "        energy_gt = energy_distance(reshaped, ground_truth)\n",
    "        result_str += f\", energy dist vs ground truth: {energy_gt:.4}\"\n",
    "    if num_iters_w2 > 0 and ground_truth is not None:\n",
    "        w2 = compute_w2(reshaped, ground_truth, num_iters_w2)\n",
    "        result_str += f\", Wasserstein-2: {w2:.4}\"\n",
    "\n",
    "    if x_test is not None and labels_test is not None:\n",
    "        acc_error, acc_best90 = test_accuracy(x_test, labels_test, samples)\n",
    "        result_str += (\n",
    "            f\", test_accuracy: {acc_error:.4}, top 90% accuracy: {acc_best90:.4}\"\n",
    "        )\n",
    "    print(result_str)\n",
    "\n",
    "\n",
    "dataset = scipy.io.loadmat(\"mcmc_data/benchmarks.mat\")\n",
    "data_name = \"banana\"\n",
    "model_logreg, data_split = get_model_and_data(dataset, data_name)\n",
    "x_train, labels_train, x_test, labels_test = data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6890aa66d4af19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:29:03.048021Z",
     "start_time": "2024-06-07T15:29:02.608319Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy bias: 0.0018354477882169817\n",
      "Ground truth shape: (65536, 4)\n",
      "test accuracy: (Array(0.551, dtype=float32), Array(0.547, dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"mcmc_data/{data_name}_ground_truth.npy\"\n",
    "\n",
    "# gt_nuts = MCMC(NUTS(model_logreg, step_size=1.0), num_warmup=2**13, num_samples=2**16)\n",
    "# gt_nuts.run(jr.PRNGKey(0), x_train, labels_train)\n",
    "# gt_logreg = vec_dict_to_array(gt_nuts.get_samples())\n",
    "# # thin the samples to 2**15\n",
    "# np.save(file_name, gt_logreg)\n",
    "\n",
    "gt_logreg = np.load(file_name)\n",
    "gt_logreg = gt_logreg[::4]\n",
    "size_gt_half = int(gt_logreg.shape[0] // 2)\n",
    "energy_bias = energy_distance(gt_logreg[:size_gt_half], gt_logreg[size_gt_half:])\n",
    "print(f\"Energy bias: {energy_bias}\")\n",
    "print(f\"Ground truth shape: {gt_logreg.shape}\")\n",
    "print(f\"test accuracy: {test_accuracy(x_test, labels_test, gt_logreg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d7bf671176fce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:29:07.393334Z",
     "start_time": "2024-06-07T15:29:07.391497Z"
    }
   },
   "outputs": [],
   "source": [
    "num_chains = 2**6\n",
    "num_samples_per_chain = 2**9\n",
    "warmup_len = 2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b866c607224c7d4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-07T15:29:07.792729Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00%|          | [00:07<?, ?%/s]"
     ]
    }
   ],
   "source": [
    "out_logreg_lmc, steps_logreg_lmc = run_lmc_numpyro(\n",
    "    jr.PRNGKey(0),\n",
    "    model_logreg,\n",
    "    (x_train, labels_train),\n",
    "    num_chains,\n",
    "    num_samples_per_chain,\n",
    "    chain_sep=0.5,\n",
    "    tol=0.5,\n",
    "    warmup_mult=warmup_len,\n",
    "    warmup_tol_mult=50,\n",
    ")\n",
    "print(jtu.tree_map(lambda x: x.shape, out_logreg_lmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370c919e1db98307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:58:13.489507Z",
     "start_time": "2024-06-07T13:58:13.097981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size: [ 598.865  691.028 4758.201 2369.001]\n",
      "Energy dist vs self: 0.000138, energy dist vs ground truth: 14.22, test_accuracy: 0.5477, top 90% accuracy: 0.5445\n"
     ]
    }
   ],
   "source": [
    "eval_logreg(\n",
    "    out_logreg_lmc, steps_logreg_lmc, gt_logreg, x_test=x_test, labels_test=labels_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47568f0f703122b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:46:32.859030Z",
     "start_time": "2024-06-07T13:46:21.819683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup: 100%|██████████| 512/512 [00:07<00:00, 69.32it/s] \n",
      "sample: 100%|██████████| 512/512 [00:01<00:00, 284.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.866943359375\n"
     ]
    }
   ],
   "source": [
    "nuts = MCMC(\n",
    "    NUTS(model_logreg),\n",
    "    num_warmup=warmup_len,\n",
    "    num_samples=num_samples_per_chain,\n",
    "    num_chains=num_chains,\n",
    "    chain_method=\"vectorized\",\n",
    ")\n",
    "nuts.warmup(jr.PRNGKey(2), x_train, labels_train, extra_fields=(\"num_steps\",))\n",
    "warmup_steps = nuts.get_extra_fields()[\"num_steps\"]\n",
    "nuts.run(jr.PRNGKey(2), x_train, labels_train, extra_fields=(\"num_steps\",))\n",
    "out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"] + warmup_steps\n",
    "geps_nuts = sum(num_steps_nuts) / (num_chains * num_samples_per_chain)\n",
    "print(geps_nuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cf79276c2501d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T14:02:33.336397Z",
     "start_time": "2024-06-07T14:02:32.890270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size: [  757.298  5807.821 23396.194 19655.407]\n",
      "Energy dist vs self: 0.01987, energy dist vs ground truth: 0.04302, test_accuracy: 0.5514, top 90% accuracy: 0.5478\n"
     ]
    }
   ],
   "source": [
    "eval_logreg(\n",
    "    out_logreg_nuts, geps_nuts, gt_logreg, x_test=x_test, labels_test=labels_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b826cca477206d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:31:46.996164Z",
     "start_time": "2024-06-07T15:31:46.990559Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_logreg_dataset(name):\n",
    "    model_logreg, data_split = get_model_and_data(dataset, name)\n",
    "    x_train, labels_train, x_test, labels_test = data_split\n",
    "\n",
    "    # Compute ground truth\n",
    "    ground_truth_filename = f\"mcmc_data/{name}_ground_truth.npy\"\n",
    "    if os.path.isfile(ground_truth_filename):\n",
    "        ground_truth = np.load(ground_truth_filename)\n",
    "    else:\n",
    "        gt_nuts = MCMC(\n",
    "            NUTS(model_logreg, step_size=1.0), num_warmup=2**13, num_samples=2**18\n",
    "        )\n",
    "        gt_nuts.run(jr.PRNGKey(0), x_train, labels_train)\n",
    "        ground_truth = vec_dict_to_array(gt_nuts.get_samples())\n",
    "        np.save(f\"mcmc_data/{name}_ground_truth.npy\", ground_truth)\n",
    "    # thin the samples to 2**16\n",
    "    factor = int(ground_truth.shape[0] // 2**16)\n",
    "    ground_truth = ground_truth[::factor]\n",
    "    assert ground_truth.shape == (\n",
    "        2**16,\n",
    "        2 + x_train.shape[1],\n",
    "    ), f\"ground_truth.shape: {ground_truth.shape}\"\n",
    "\n",
    "    size_gt_half = int(ground_truth.shape[0] // 2)\n",
    "    gt_energy_bias = energy_distance(\n",
    "        ground_truth[:size_gt_half], ground_truth[size_gt_half:]\n",
    "    )\n",
    "    print(f\"Ground truth energy bias: {gt_energy_bias:.4}\")\n",
    "    num_chains = 2**6\n",
    "    num_samples_per_chain = 2**9\n",
    "    warmup_len = 2**9\n",
    "\n",
    "    out_logreg_lmc, steps_logreg_lmc = run_lmc_numpyro(\n",
    "        jr.PRNGKey(0),\n",
    "        model_logreg,\n",
    "        (x_train, labels_train),\n",
    "        num_chains,\n",
    "        num_samples_per_chain,\n",
    "        chain_sep=0.5,\n",
    "        tol=0.5,\n",
    "        warmup_mult=warmup_len,\n",
    "        warmup_tol_mult=50,\n",
    "    )\n",
    "\n",
    "    eval_logreg(\n",
    "        out_logreg_lmc,\n",
    "        steps_logreg_lmc,\n",
    "        ground_truth,\n",
    "        x_test=x_test,\n",
    "        labels_test=labels_test,\n",
    "    )\n",
    "\n",
    "    nuts = MCMC(\n",
    "        NUTS(model_logreg),\n",
    "        num_warmup=warmup_len,\n",
    "        num_samples=num_samples_per_chain,\n",
    "        num_chains=num_chains,\n",
    "        chain_method=\"vectorized\",\n",
    "    )\n",
    "    nuts.warmup(jr.PRNGKey(2), x_train, labels_train, extra_fields=(\"num_steps\",))\n",
    "    warmup_steps = nuts.get_extra_fields()[\"num_steps\"]\n",
    "    nuts.run(jr.PRNGKey(2), x_train, labels_train, extra_fields=(\"num_steps\",))\n",
    "    out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "    num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"] + warmup_steps\n",
    "    geps_nuts = sum(num_steps_nuts) / (num_chains * num_samples_per_chain)\n",
    "    print(f\"NUTS: Gradient evals per output: {geps_nuts:.4}\")\n",
    "    eval_logreg(\n",
    "        out_logreg_nuts, geps_nuts, ground_truth, x_test=x_test, labels_test=labels_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6851c76c27702f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:31:48.693516Z",
     "start_time": "2024-06-07T15:31:48.691551Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"banana\",\n",
    "    \"breast_cancer\",\n",
    "    \"diabetis\",\n",
    "    \"flare_solar\",\n",
    "    \"german\",\n",
    "    \"heart\",\n",
    "    \"image\",\n",
    "    \"ringnorm\",\n",
    "    \"splice\",\n",
    "    \"thyroid\",\n",
    "    \"titanic\",\n",
    "    \"twonorm\",\n",
    "    \"waveform\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e926ca753859d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-07T15:31:49.155841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== banana ====================\n",
      "Data shape: (5300, 2)\n",
      "Ground truth energy bias: 0.001835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████| [00:31<00:00,  3.19%/s]\n",
      "100.00%|██████████| [07:41<00:00,  4.61s/%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMC: gradient evaluations per output: 142.9\n",
      "Effective sample size: [ 926.834  684.512 4671.124 2378.13 ]\n",
      "Energy dist vs self: 0.001877, energy dist vs ground truth: 14.04, test_accuracy: 0.5479, top 90% accuracy: 0.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup: 100%|██████████| 512/512 [00:07<00:00, 70.26it/s] \n",
      "sample: 100%|██████████| 512/512 [00:01<00:00, 285.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS: Gradient evals per output: 6.867\n",
      "Effective sample size: [  757.298  5807.821 23396.194 19655.407]\n",
      "Energy dist vs self: 0.01987, energy dist vs ground truth: 0.007543, test_accuracy: 0.5514, top 90% accuracy: 0.5478\n",
      "\n",
      "==================== breast_cancer ====================\n",
      "Data shape: (263, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 270336/270336 [13:00<00:00, 346.30it/s, 15 steps of size 4.14e-01. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth energy bias: 5.265e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00%|          | [04:51<?, ?%/s]"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "for name in names:\n",
    "    print(f\"==================== {name} ====================\")\n",
    "    run_logreg_dataset(name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0934ba3585949a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

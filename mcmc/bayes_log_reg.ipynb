{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:43:53.339494Z",
     "start_time": "2024-04-25T16:43:51.370286Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import ot\n",
    "import scipy\n",
    "from numpyro import diagnostics, distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro.infer.util import initialize_model\n",
    "\n",
    "from mcmc import run_lmc\n",
    "\n",
    "\n",
    "jnp.set_printoptions(precision=4, suppress=True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "def get_model_and_data(data, name):\n",
    "    dset = data[name][0, 0]\n",
    "    x = dset[\"x\"]\n",
    "    labels = dset[\"t\"]\n",
    "    n, data_dim = x.shape\n",
    "    n_train = min(int(n / 2), 500)\n",
    "    x_train = x[:n_train]\n",
    "    labels_train = labels[:n_train]\n",
    "    x_test = x[n_train:]\n",
    "    labels_test = labels[n_train:]\n",
    "\n",
    "    def model():\n",
    "        alpha = numpyro.sample(\"alpha\", dist.Exponential(0.01))\n",
    "        W = numpyro.sample(\"W\", dist.Normal(jnp.zeros(data_dim), 1.0 / alpha))\n",
    "        logits = jnp.sum(W * x_train, axis=-1)\n",
    "        return numpyro.sample(\"obs\", dist.Bernoulli(logits=logits), obs=labels_train)\n",
    "\n",
    "    return model, (x_train, labels_train, x_test, labels_test)\n",
    "\n",
    "\n",
    "data = scipy.io.loadmat(\"mcmc_data/benchmarks.mat\")\n",
    "\n",
    "model_logreg, data_split = get_model_and_data(data, \"banana\")\n",
    "\n",
    "logreg_info = initialize_model(jr.PRNGKey(0), model_logreg)\n",
    "\n",
    "\n",
    "def dict_to_array(dct: dict):\n",
    "    alpha = dct[\"alpha\"]\n",
    "\n",
    "    return jnp.concatenate([jnp.expand_dims(alpha, alpha.ndim), dct[\"W\"]], axis=-1)\n",
    "\n",
    "\n",
    "vec_dict_to_array = jax.jit(jax.vmap(dict_to_array, in_axes=0, out_axes=0))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def array_to_dict(arr: jnp.ndarray):\n",
    "    return {\"alpha\": arr[0], \"W\": arr[1:]}\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def potential_fn(arr: jnp.ndarray):\n",
    "    dct = array_to_dict(arr)\n",
    "    return logreg_info.potential_fn(dct)\n",
    "\n",
    "\n",
    "arr0 = dict_to_array(logreg_info.param_info.z)\n",
    "\n",
    "print(jax.devices(\"cuda\"))\n",
    "\n",
    "\n",
    "def compute_w2(x1, x2):\n",
    "    source_samples = np.array(x1)\n",
    "    target_samples = np.array(x2)\n",
    "    source_weights = np.ones(source_samples.shape[0]) / source_samples.shape[0]\n",
    "    target_weights = np.ones(target_samples.shape[0]) / target_samples.shape[0]\n",
    "    mm = ot.dist(source_samples, target_samples)\n",
    "    return ot.emd2(source_weights, target_weights, mm, numItermax=1e5)\n",
    "\n",
    "\n",
    "def eval_logreg(samples, evals_per_sample, ground_truth=None):\n",
    "    if isinstance(samples, dict):\n",
    "        samples = vec_dict_to_array(samples)\n",
    "    ess = diagnostics.effective_sample_size(samples)\n",
    "    print(f\"Effective sample size: {ess}\")\n",
    "    print(\n",
    "        f\"Gradient evals per effective sample:\"\n",
    "        f\" {evals_per_sample * samples.shape[0]/ess}\"\n",
    "    )\n",
    "    if ground_truth is None:\n",
    "        return\n",
    "    sample_dim = samples.shape[-1]\n",
    "    reshaped = jnp.reshape(samples, (-1, sample_dim))\n",
    "\n",
    "    w2 = compute_w2(reshaped, ground_truth)\n",
    "    print(f\"W2 distance: {w2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6890aa66d4af19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:06:29.230728Z",
     "start_time": "2024-04-25T16:06:29.228386Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gt_nuts = MCMC(NUTS(model_logreg, step_size=0.125),\n",
    "#                num_warmup=2**8, num_samples=2**14)\n",
    "# gt_nuts.run(jr.PRNGKey(0))\n",
    "# gt_logreg = vec_dict_to_array(gt_nuts.get_samples())\n",
    "# np.save(\"mcmc_data/banana_ground_truth.npy\", gt_logreg)\n",
    "gt_logreg = np.load(\"mcmc_data/banana_ground_truth.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b866c607224c7d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:36:46.197252Z",
     "start_time": "2024-04-25T16:36:33.116854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps warmup: 32.5078125, steps mcmc: 883.0078125, gradient evaluations per output: 7.1524658203125\n",
      "(128, 256, 10)\n"
     ]
    }
   ],
   "source": [
    "num_chains = 2**7\n",
    "num_samples_per_chain = 2**8\n",
    "out_logreg_lmc, steps_logreg_lmc = run_lmc(\n",
    "    jr.PRNGKey(0),\n",
    "    potential_fn,\n",
    "    arr0,\n",
    "    num_chains,\n",
    "    num_samples_per_chain,\n",
    "    0.1,\n",
    "    5.0,\n",
    "    warmup_mult=32.0,\n",
    "    warmup_tol_mult=8.0,\n",
    ")\n",
    "print(out_logreg_lmc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370c919e1db98307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:07:06.204580Z",
     "start_time": "2024-04-25T16:06:34.267232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size: [  749.9436  5597.1612 14985.1067]\n",
      "Gradient evals per effective sample: [12.8984  1.7282  0.6455]\n",
      "W2 distance: 0.02424249648306309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/PycharmProjects/diffrax_STLA/venv/lib/python3.11/site-packages/ot/lp/__init__.py:571: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "eval_logreg(out_logreg_lmc, steps_logreg_lmc, gt_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47568f0f703122b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:08:07.384563Z",
     "start_time": "2024-04-25T16:07:06.205686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 264/264 [00:59<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.700408935546875\n"
     ]
    }
   ],
   "source": [
    "nuts = MCMC(\n",
    "    NUTS(model_logreg),\n",
    "    num_warmup=2**3,\n",
    "    num_samples=num_samples_per_chain,\n",
    "    num_chains=num_chains,\n",
    "    chain_method=\"vectorized\",\n",
    ")\n",
    "nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)\n",
    "print(geps_nuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65cf79276c2501d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:08:38.286240Z",
     "start_time": "2024-04-25T16:08:07.385089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size: [    nan 65.1355     nan]\n",
      "Gradient evals per effective sample: [    nan 21.0277     nan]\n",
      "W2 distance: 0.03975801461724085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/PycharmProjects/diffrax_STLA/venv/lib/python3.11/site-packages/ot/lp/__init__.py:571: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "eval_logreg(out_logreg_nuts, geps_nuts, gt_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b826cca477206d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:43:58.248572Z",
     "start_time": "2024-04-25T16:43:58.244707Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_logreg_dataset(name):\n",
    "    model_logreg, data_split = get_model_and_data(data, name)\n",
    "    logreg_info = initialize_model(jr.PRNGKey(0), model_logreg)\n",
    "    arr0 = dict_to_array(logreg_info.param_info.z)\n",
    "\n",
    "    @jax.jit\n",
    "    def _potential_fn(arr: jnp.ndarray):\n",
    "        dct = array_to_dict(arr)\n",
    "        return logreg_info.potential_fn(dct)\n",
    "\n",
    "    # Compute ground truth\n",
    "    ground_truth_filename = f\"mcmc_data/{name}_ground_truth.npy\"\n",
    "    if os.path.isfile(ground_truth_filename):\n",
    "        gt_logreg = np.load(ground_truth_filename)\n",
    "    else:\n",
    "        gt_nuts = MCMC(\n",
    "            NUTS(model_logreg, step_size=0.125), num_warmup=2**8, num_samples=2**14\n",
    "        )\n",
    "        gt_nuts.run(jr.PRNGKey(0))\n",
    "        gt_logreg = vec_dict_to_array(gt_nuts.get_samples())\n",
    "        np.save(f\"mcmc_data/{name}_ground_truth.npy\", gt_logreg)\n",
    "\n",
    "    num_chains = 2**7\n",
    "    num_samples_per_chain = 2**8\n",
    "\n",
    "    print(\"LMC\")\n",
    "    out_logreg_lmc, steps_logreg_lmc = run_lmc(\n",
    "        jr.PRNGKey(0),\n",
    "        _potential_fn,\n",
    "        arr0,\n",
    "        num_chains,\n",
    "        num_samples_per_chain,\n",
    "        0.1,\n",
    "        5.0,\n",
    "        warmup_mult=32.0,\n",
    "        warmup_tol_mult=16.0,\n",
    "    )\n",
    "    eval_logreg(out_logreg_lmc, steps_logreg_lmc, gt_logreg)\n",
    "\n",
    "    print(\"NUTS\")\n",
    "    nuts = MCMC(\n",
    "        NUTS(model_logreg),\n",
    "        num_warmup=2**6,\n",
    "        num_samples=num_samples_per_chain,\n",
    "        num_chains=num_chains,\n",
    "        chain_method=\"vectorized\",\n",
    "    )\n",
    "    nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "    out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "    num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "    geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)\n",
    "    print(f\"Gradient evals per effective sample (NUTS): {geps_nuts}\")\n",
    "    eval_logreg(out_logreg_nuts, geps_nuts, gt_logreg)\n",
    "\n",
    "    print(\"LMC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6851c76c27702f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:39:53.139354Z",
     "start_time": "2024-04-25T16:39:53.137117Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"banana\",\n",
    "    \"breast_cancer\",\n",
    "    \"diabetis\",\n",
    "    \"flare_solar\",\n",
    "    \"german\",\n",
    "    \"heart\",\n",
    "    \"image\",\n",
    "    \"ringnorm\",\n",
    "    \"splice\",\n",
    "    \"thyroid\",\n",
    "    \"titanic\",\n",
    "    \"twonorm\",\n",
    "    \"waveform\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e926ca753859d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-25T16:39:53.946977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== breast_cancer ====================\n",
      "Steps warmup: 25.6640625, steps mcmc: 910.875, gradient evaluations per output: 7.31671142578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 320/320 [00:32<00:00,  9.75it/s]\n",
      "sample: 100%|██████████| 16640/16640 [00:56<00:00, 295.60it/s, 3 steps of size 8.17e-06. acc. prob=0.83]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS\n",
      "Effective sample size: [    nan     nan 65.2196     nan     nan     nan     nan     nan     nan\n",
      "     nan]\n",
      "Gradient evals per effective sample: [   nan    nan 17.012    nan    nan    nan    nan    nan    nan    nan]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for name in names:\n",
    "        print(f\"==================== {name} ====================\")\n",
    "        run_logreg_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ba3d7e0e16a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

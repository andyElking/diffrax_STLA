{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T14:58:25.646797Z",
     "start_time": "2024-04-25T14:58:24.601465Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import ot\n",
    "import scipy\n",
    "from numpyro import diagnostics, distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro.infer.util import initialize_model\n",
    "from scipy import stats\n",
    "\n",
    "from mcmc import run_sortmc\n",
    "\n",
    "\n",
    "jnp.set_printoptions(precision=4, suppress=True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "def log_p_normal(x):\n",
    "    return 0.5 * jnp.dot(x, x)\n",
    "\n",
    "\n",
    "STD_X = 3.0\n",
    "\n",
    "\n",
    "def std_y(x):\n",
    "    return jnp.exp(jax.lax.stop_gradient(x) / 2.0)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def potential_funnel(x):\n",
    "    z_term = x[0] ** 2 / (2.0 * STD_X**2)\n",
    "    y_term = jnp.sum(x[1:] ** 2) / (2.0 * std_y(x[0]) ** 2)\n",
    "    return z_term + y_term\n",
    "\n",
    "\n",
    "def funnel_model(dim=10):\n",
    "    x = numpyro.sample(\"x\", dist.Normal(jnp.zeros((1,)), STD_X))\n",
    "    numpyro.sample(\"y\", dist.Normal(jnp.zeros(dim - 1), std_y(x)))\n",
    "\n",
    "\n",
    "def dict_to_array(dct: dict):\n",
    "    x = jnp.expand_dims(dct[\"x\"], dct[\"x\"].ndim)\n",
    "    return jnp.concatenate([x, dct[\"y\"]], axis=-1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "@jax.vmap\n",
    "def funnel_true_samples(keys):\n",
    "    key_x, key_y = jr.split(keys, 2)\n",
    "    x = jr.normal(key_x, shape=(1,)) * STD_X\n",
    "    y = jr.normal(key_y, shape=(9,)) * std_y(x)\n",
    "    return jnp.concatenate([x, y])\n",
    "\n",
    "\n",
    "def rescale_funnel(x):\n",
    "    return jnp.concatenate([x[:1] / STD_X, x[1:] / std_y(x[0])])\n",
    "\n",
    "\n",
    "vec_rescale_funnel = jax.jit(jax.vmap(rescale_funnel, in_axes=0))\n",
    "\n",
    "x0_funnel = jnp.zeros((10,), dtype=jnp.float64)\n",
    "\n",
    "\n",
    "FUNNEL_LIMS = (-10.0, 10.0)\n",
    "\n",
    "\n",
    "def draw_funnel(samples):\n",
    "    samples_rshp = jnp.reshape(samples, (-1, 10))\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.scatter(samples_rshp[:, 0], samples_rshp[:, 1], alpha=0.2, s=8.0)\n",
    "    ax.set(xlim=FUNNEL_LIMS, ylim=FUNNEL_LIMS)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_funnel(samples, grad_evals_per_sample: float = 0.0):\n",
    "    def avg(x):\n",
    "        x = jnp.array(x)\n",
    "        weights = jnp.array([9] + [1] * 9, dtype=jnp.float64) / 18.0\n",
    "        return jnp.dot(x, weights)\n",
    "\n",
    "    def matrix_avg(x):\n",
    "        x = jnp.array(x)\n",
    "        one_dim = jax.vmap(avg, in_axes=0)(x)\n",
    "        return avg(one_dim)\n",
    "\n",
    "    samples_rshp = jnp.reshape(samples, (-1, 10))\n",
    "    means = jnp.mean(samples_rshp, axis=0)\n",
    "    max_mean_err = jnp.max(jnp.abs(means))\n",
    "    avg_mean_err = avg(jnp.abs(means))\n",
    "    samples_rescaled = vec_rescale_funnel(samples_rshp)\n",
    "    cov = jnp.cov(samples_rescaled, rowvar=False)\n",
    "    cov_err = jnp.abs(cov - jnp.eye(10))\n",
    "    max_cov_err = jnp.max(cov_err)\n",
    "    avg_cov_err = matrix_avg(cov_err)\n",
    "    ref_dist = stats.norm(loc=0.0, scale=1.0)\n",
    "    pvals = []\n",
    "    for i in range(10):\n",
    "        _, pval = stats.kstest(samples_rescaled[:, i], ref_dist.cdf)\n",
    "        pvals.append(pval)\n",
    "    min_pval = min(pvals)\n",
    "    avg_pval = avg(pvals)\n",
    "    if samples.ndim > 2:\n",
    "        ess = diagnostics.effective_sample_size(samples) / samples_rshp.shape[0]\n",
    "        min_ess = jnp.min(ess)\n",
    "        avg_ess = avg(ess)\n",
    "        # compute the number of gradient evaluations per effective sample\n",
    "        if grad_evals_per_sample > 0:\n",
    "            gepes = grad_evals_per_sample / avg_ess\n",
    "            print(f\"Gradient evaluations per effective sample: {gepes}\")\n",
    "    else:\n",
    "        ess = 1.0\n",
    "        min_ess = 1.0\n",
    "        avg_ess = 1.0\n",
    "    print(\n",
    "        f\"Max mean err: {max_mean_err:.4}, max cov err: {max_cov_err:.4},\"\n",
    "        f\" min_pval: {min_pval:.4}, min_ess {min_ess:.4}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Avg mean err: {avg_mean_err:.4}, avg cov err: {avg_cov_err:.4},\"\n",
    "        f\" avg_pval: {avg_pval:.4}, avg_ess {avg_ess:.4}\"\n",
    "    )\n",
    "\n",
    "    draw_funnel(samples_rshp)\n",
    "\n",
    "    return means, cov, pvals, ess"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171938cf83d60ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:27:24.256047Z",
     "start_time": "2024-03-01T15:25:39.254827Z"
    },
    "collapsed": false
   },
   "source": [
    "# geps stands for gradient evals per sample\n",
    "ys_funnel_sort, geps_sort = run_sortmc(\n",
    "    jr.PRNGKey(0),\n",
    "    potential_funnel,\n",
    "    x0_funnel,\n",
    "    64,\n",
    "    2**7,\n",
    "    2.0,\n",
    "    2.0**-6,\n",
    "    warmup_mult=16.0,\n",
    "    warmup_tol_mult=4.0,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d53901554f2afac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:33:32.476685Z",
     "start_time": "2024-03-01T15:32:56.632921Z"
    },
    "collapsed": false
   },
   "source": [
    "num_chains = 64\n",
    "x0_funnel_broadcast = jnp.broadcast_to(x0_funnel, (num_chains,) + x0_funnel.shape)\n",
    "\n",
    "kernel = NUTS(funnel_model, step_size=2.0)\n",
    "nuts_funnel = MCMC(\n",
    "    kernel,\n",
    "    num_warmup=16,\n",
    "    num_samples=2**7,\n",
    "    num_chains=num_chains,\n",
    "    chain_method=\"vectorized\",\n",
    ")\n",
    "nuts_funnel.run(\n",
    "    jr.PRNGKey(0),\n",
    "    extra_fields=(\"num_steps\",),\n",
    "    init_params={\n",
    "        \"x\": np.zeros((num_chains,), dtype=np.float64),\n",
    "        \"y\": np.zeros((num_chains, 9), dtype=np.float64),\n",
    "    },\n",
    ")\n",
    "ys_funnel_nuts_dict = nuts_funnel.get_samples(group_by_chain=True)\n",
    "ys_funnel_nuts = dict_to_array(ys_funnel_nuts_dict)\n",
    "steps_nuts = nuts_funnel.get_extra_fields()[\"num_steps\"]\n",
    "geps_nuts = sum(steps_nuts) / len(steps_nuts)\n",
    "print(geps_nuts)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d06c9ffcc37307df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T16:11:50.957400Z",
     "start_time": "2024-03-01T16:11:50.955113Z"
    },
    "collapsed": false
   },
   "source": [
    "print(geps_nuts)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6b10b427352107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T16:34:23.487769Z",
     "start_time": "2024-03-01T16:32:47.715204Z"
    },
    "collapsed": false
   },
   "source": [
    "ys_funnel_euler, geps_euler = run_sortmc(\n",
    "    jr.PRNGKey(0),\n",
    "    potential_funnel,\n",
    "    x0_funnel,\n",
    "    64,\n",
    "    2**7,\n",
    "    2.0,\n",
    "    2.0**-6,\n",
    "    warmup_mult=16.0,\n",
    "    warmup_tol_mult=4.0,\n",
    "    use_sort_adaptive=False,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ef81d8adc3692a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:39:36.528565Z",
     "start_time": "2024-03-01T15:39:36.344681Z"
    },
    "collapsed": false
   },
   "source": [
    "_ = evaluate_funnel(ys_funnel_nuts, geps_nuts)\n",
    "# ani_nuts, _, _ = animated_funnel_plot(ys_funnel_nuts)\n",
    "# ani_nuts.save(\"funnel_nuts.gif\", writer=\"pillow\")\n",
    "print(geps_nuts)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992d859497c13580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T16:36:26.104451Z",
     "start_time": "2024-03-01T16:36:26.022920Z"
    },
    "collapsed": false
   },
   "source": [
    "ys_funnel_euler = jnp.clip(ys_funnel_euler, -20, 20)\n",
    "\n",
    "_ = evaluate_funnel(ys_funnel_euler, geps_euler)\n",
    "# ani_euler, _, _ = animated_funnel_plot(ys_funnel_euler)\n",
    "# ani_euler.save(\"funnel_euler.gif\", writer=\"pillow\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3b99fb5a58f915",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:39:42.748207Z",
     "start_time": "2024-03-01T15:39:42.627502Z"
    },
    "collapsed": false
   },
   "source": [
    "_ = evaluate_funnel(ys_funnel_sort, geps_sort)\n",
    "# ani_sort, _, _ = animated_funnel_plot(ys_funnel_sort)\n",
    "# ani_sort.save(\"funnel_sort.gif\", writer=\"pillow\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bdcf132d111384a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T16:22:23.893186Z",
     "start_time": "2024-03-01T16:22:23.683471Z"
    },
    "collapsed": false
   },
   "source": [
    "# True samples\n",
    "keys = jr.split(jr.PRNGKey(0), 2**13)\n",
    "ys_funnel_true = funnel_true_samples(keys)\n",
    "_ = evaluate_funnel(ys_funnel_true)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c99fc455110090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T11:50:26.477044Z",
     "start_time": "2024-02-29T11:50:26.414786Z"
    },
    "collapsed": false
   },
   "source": [
    "def get_model_and_data(data, name):\n",
    "    dset = data[name][0, 0]\n",
    "    x = dset[\"x\"]\n",
    "    labels = dset[\"t\"]\n",
    "    n, data_dim = x.shape\n",
    "    n_train = min(int(n / 2), 500)\n",
    "    x_train = x[:n_train]\n",
    "    labels_train = labels[:n_train]\n",
    "    x_test = x[n_train:]\n",
    "    labels_test = labels[n_train:]\n",
    "\n",
    "    def model():\n",
    "        alpha = numpyro.sample(\"alpha\", dist.Exponential(0.01))\n",
    "        W = numpyro.sample(\"W\", dist.Normal(jnp.zeros(data_dim), 1.0 / alpha))\n",
    "        logits = jnp.sum(W * x_train, axis=-1)\n",
    "        return numpyro.sample(\"obs\", dist.Bernoulli(logits=logits), obs=labels_train)\n",
    "\n",
    "    return model, (x_train, labels_train, x_test, labels_test)\n",
    "\n",
    "\n",
    "data = scipy.io.loadmat(\"mcmc_data/benchmarks.mat\")\n",
    "\n",
    "model_logreg, data_split = get_model_and_data(data, \"banana\")\n",
    "\n",
    "logreg_info = initialize_model(jr.PRNGKey(0), model_logreg)\n",
    "\n",
    "\n",
    "def dict_to_array(dct: dict):\n",
    "    alpha = dct[\"alpha\"]\n",
    "\n",
    "    return jnp.concatenate([jnp.expand_dims(alpha, alpha.ndim), dct[\"W\"]], axis=-1)\n",
    "\n",
    "\n",
    "vec_dict_to_array = jax.vmap(dict_to_array, in_axes=0, out_axes=0)\n",
    "\n",
    "\n",
    "def array_to_dict(arr: jnp.ndarray):\n",
    "    return {\"alpha\": arr[0], \"W\": arr[1:]}\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def potential_fn(arr: jnp.ndarray):\n",
    "    dct = array_to_dict(arr)\n",
    "    return logreg_info.potential_fn(dct)\n",
    "\n",
    "\n",
    "arr0 = dict_to_array(logreg_info.param_info.z)\n",
    "\n",
    "print(jax.devices(\"cuda\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b866c607224c7d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:06:47.911936Z",
     "start_time": "2024-02-28T20:05:14.437184Z"
    },
    "collapsed": false
   },
   "source": [
    "out_logreg_sort, steps_logreg_sort = run_sortmc(\n",
    "    jr.PRNGKey(0),\n",
    "    potential_fn,\n",
    "    arr0,\n",
    "    64,\n",
    "    2**7,\n",
    "    1.0,\n",
    "    0.25,\n",
    "    warmup_mult=8.0,\n",
    "    warmup_tol_mult=4.0,\n",
    ")\n",
    "print(out_logreg_sort.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61431a978ffea2ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:06:47.915565Z",
     "start_time": "2024-02-28T20:06:47.912498Z"
    },
    "collapsed": false
   },
   "source": [
    "def compute_w2(x1, x2):\n",
    "    source_samples = np.array(x1)\n",
    "    target_samples = np.array(x2)\n",
    "    source_weights = np.ones(source_samples.shape[0]) / source_samples.shape[0]\n",
    "    target_weights = np.ones(target_samples.shape[0]) / target_samples.shape[0]\n",
    "    mm = ot.dist(source_samples, target_samples)\n",
    "    return ot.emd2(source_weights, target_weights, mm)\n",
    "\n",
    "\n",
    "def eval_logreg(samples, evals_per_sample, ground_truth=None):\n",
    "    if isinstance(samples, dict):\n",
    "        samples = vec_dict_to_array(samples)\n",
    "    ess = diagnostics.effective_sample_size(samples)\n",
    "    print(f\"Gradient evals per effective sample: {evals_per_sample/ess}\")\n",
    "    if ground_truth is None:\n",
    "        return\n",
    "    sample_dim = samples.shape[-1]\n",
    "    reshaped = jnp.reshape(samples, (-1, sample_dim))\n",
    "\n",
    "    w2 = compute_w2(reshaped, ground_truth)\n",
    "    print(f\"W2 distance: {w2}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47568f0f703122b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:06:47.925433Z",
     "start_time": "2024-02-28T20:06:47.916202Z"
    },
    "collapsed": false
   },
   "source": [
    "nuts = MCMC(\n",
    "    NUTS(model_logreg),\n",
    "    num_warmup=2**3,\n",
    "    num_samples=2**7,\n",
    "    num_chains=64,\n",
    "    chain_method=\"vectorized\",\n",
    ")\n",
    "gt_nuts = MCMC(NUTS(model_logreg, step_size=0.25), num_warmup=2**8, num_samples=2**14)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124662ed2c2ff8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:07:13.406702Z",
     "start_time": "2024-02-28T20:06:47.925846Z"
    },
    "collapsed": false
   },
   "source": [
    "nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cf79276c2501d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:07:13.463903Z",
     "start_time": "2024-02-28T20:07:13.407369Z"
    },
    "collapsed": false
   },
   "source": [
    "eval_logreg(out_logreg_nuts, geps_nuts)\n",
    "eval_logreg(out_logreg_sort, steps_logreg_sort)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6890aa66d4af19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:08:34.195976Z",
     "start_time": "2024-02-28T20:07:13.464453Z"
    },
    "collapsed": false
   },
   "source": [
    "gt_nuts.run(jr.PRNGKey(0))\n",
    "gt_logreg = vec_dict_to_array(gt_nuts.get_samples())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b826cca477206d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T20:08:34.199647Z",
     "start_time": "2024-02-28T20:08:34.196651Z"
    },
    "collapsed": false
   },
   "source": [
    "def run_logreg_dataset(name):\n",
    "    model_logreg, data_split = get_model_and_data(data, name)\n",
    "    logreg_info = initialize_model(jr.PRNGKey(0), model_logreg)\n",
    "    arr0 = dict_to_array(logreg_info.param_info.z)\n",
    "    out_logreg_sort, steps_logreg_sort = run_sortmc(\n",
    "        jr.PRNGKey(0),\n",
    "        potential_fn,\n",
    "        arr0,\n",
    "        64,\n",
    "        2**7,\n",
    "        1.0,\n",
    "        2.0**-2,\n",
    "        warmup_mult=8.0,\n",
    "        warmup_tol_mult=4.0,\n",
    "    )\n",
    "    nuts = MCMC(\n",
    "        NUTS(model_logreg),\n",
    "        num_warmup=2**4,\n",
    "        num_samples=2**7,\n",
    "        num_chains=64,\n",
    "        chain_method=\"vectorized\",\n",
    "    )\n",
    "    nuts.run(jr.PRNGKey(0), extra_fields=(\"num_steps\",))\n",
    "    out_logreg_nuts = nuts.get_samples(group_by_chain=True)\n",
    "    num_steps_nuts = nuts.get_extra_fields()[\"num_steps\"]\n",
    "    geps_nuts = sum(num_steps_nuts) / len(num_steps_nuts)\n",
    "    gt_nuts = MCMC(\n",
    "        NUTS(model_logreg, step_size=0.25), num_warmup=2**8, num_samples=2**14\n",
    "    )\n",
    "    gt_nuts.run(jr.PRNGKey(0))\n",
    "    gt_logreg = vec_dict_to_array(gt_nuts.get_samples())\n",
    "    eval_logreg(out_logreg_nuts, geps_nuts, gt_logreg)\n",
    "    eval_logreg(out_logreg_sort, steps_logreg_sort, gt_logreg)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f1c4ad0944205",
   "metadata": {
    "collapsed": false
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

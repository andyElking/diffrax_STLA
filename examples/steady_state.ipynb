{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steady states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how to use Diffrax to solve an ODE until it reaches a steady state. The key feature will be the use of event handling to detect that the steady state has been reached.\n",
    "\n",
    "In addition, for this example we need to backpropagate through the procedure of finding a steady state. We can do this efficiently using the implicit function theorem.\n",
    "\n",
    "This example is available as a Jupyter notebook [here](https://github.com/patrick-kidger/diffrax/blob/main/examples/steady_state.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execute": {
     "shell": {
      "execute_reply": "2022-07-15T17:49:27.190533+00:00"
     }
    },
    "iopub": {
     "execute_input": "2022-07-15T17:46:56.174218+00:00",
     "status": {
      "busy": "2022-07-15T17:46:56.173283+00:00",
      "idle": "2022-07-15T17:49:27.191890+00:00"
     }
    }
   },
   "source": [
    "import diffrax\n",
    "import equinox as eqx  # https://github.com/patrick-kidger/equinox\n",
    "import jax.numpy as jnp\n",
    "import optax  # https://github.com/deepmind/optax"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execute": {
     "shell": {
      "execute_reply": "2022-07-15T17:49:27.200260+00:00"
     }
    },
    "iopub": {
     "execute_input": "2022-07-15T17:49:27.194682+00:00",
     "status": {
      "busy": "2022-07-15T17:49:27.194211+00:00",
      "idle": "2022-07-15T17:49:27.201694+00:00"
     }
    }
   },
   "source": [
    "class ExponentialDecayToSteadyState(eqx.Module):\n",
    "    steady_state: float\n",
    "\n",
    "    def __call__(self, t, y, args):\n",
    "        return self.steady_state - y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execute": {
     "shell": {
      "execute_reply": "2022-07-15T17:49:27.210168+00:00"
     }
    },
    "iopub": {
     "execute_input": "2022-07-15T17:49:27.203780+00:00",
     "status": {
      "busy": "2022-07-15T17:49:27.202937+00:00",
      "idle": "2022-07-15T17:49:27.211528+00:00"
     }
    }
   },
   "source": [
    "def loss(model, target_steady_state):\n",
    "    term = diffrax.ODETerm(model)\n",
    "    solver = diffrax.Tsit5()\n",
    "    t0 = 0\n",
    "    t1 = jnp.inf\n",
    "    dt0 = None\n",
    "    y0 = 1.0\n",
    "    max_steps = None\n",
    "    controller = diffrax.PIDController(rtol=1e-3, atol=1e-6)\n",
    "    event = diffrax.SteadyStateEvent()\n",
    "    adjoint = diffrax.ImplicitAdjoint()\n",
    "    # This combination of event, t1, max_steps, adjoint is particularly\n",
    "    # natural: we keep integration forever until we hit the event, with\n",
    "    # no maximum time or number of steps. Backpropagation happens via\n",
    "    # the implicit function theorem.\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        term,\n",
    "        solver,\n",
    "        t0,\n",
    "        t1,\n",
    "        dt0,\n",
    "        y0,\n",
    "        max_steps=max_steps,\n",
    "        stepsize_controller=controller,\n",
    "        discrete_terminating_event=event,\n",
    "        adjoint=adjoint,\n",
    "    )\n",
    "    (y1,) = sol.ys\n",
    "    return (y1 - target_steady_state) ** 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execute": {
     "shell": {
      "execute_reply": "2022-07-15T17:49:28.926507+00:00"
     }
    },
    "iopub": {
     "execute_input": "2022-07-15T17:49:27.214972+00:00",
     "status": {
      "busy": "2022-07-15T17:49:27.214240+00:00",
      "idle": "2022-07-15T17:49:28.927742+00:00"
     }
    }
   },
   "source": [
    "model = ExponentialDecayToSteadyState(\n",
    "    jnp.array(0.0)\n",
    ")  # initial steady state guess is 0.\n",
    "# target steady state is 0.76\n",
    "target_steady_state = jnp.array(0.76)\n",
    "optim = optax.sgd(1e-2, momentum=0.7, nesterov=True)\n",
    "opt_state = optim.init(model)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, opt_state, target_steady_state):\n",
    "    grads = eqx.filter_grad(loss)(model, target_steady_state)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, opt_state\n",
    "\n",
    "\n",
    "for step in range(100):\n",
    "    model, opt_state = make_step(model, opt_state, target_steady_state)\n",
    "    print(f\"Step: {step} Steady State: {model.steady_state}\")\n",
    "print(f\"Target: {target_steady_state}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
